{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "256a9376-dd17-4dbf-bd86-e388a36284cd",
   "metadata": {},
   "source": [
    "# Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "220ddbb4-0648-4ceb-9a7b-b9a641e5718d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchaudio.transforms import MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b4a0827b-35f5-4b50-990a-20ed975128e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.dirname(os.getcwd())+\"/data\"\n",
    "os.chdir(data_path)\n",
    "chord_labels = os.listdir(os.path.join(data_path, \"Train\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0964dc3d-9487-4a95-a2dd-4cff000c73b2",
   "metadata": {},
   "source": [
    "# Define a custom Dataset in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4863e1f7-3ad3-460c-9fae-1c52277de0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class WAVDataset(Dataset):\n",
    "    def __init__(self, data_dir, audio_sample_rate):\n",
    "        self.data_dir = data_dir\n",
    "        self.sampling_rate = audio_sample_rate\n",
    "        #Tune n_mels, default is 128\n",
    "        self.transform = MFCC(sample_rate=audio_sample_rate, n_mfcc=40, melkwargs={\"n_mels\": 64, \"n_fft\":400})\n",
    "        \n",
    "        #Store file paths and target labels\n",
    "        self.files = []\n",
    "        self.labels = []\n",
    "        self.encoded_labels = []\n",
    "\n",
    "        # Walk through the directories to get audio file paths and labels\n",
    "        for label in os.listdir(data_dir):\n",
    "            label_dir = os.path.join(data_dir, label)\n",
    "            if os.path.isdir(label_dir):\n",
    "                for audio_file in os.listdir(label_dir):\n",
    "                    if audio_file.endswith('.wav'):\n",
    "                        audio_file_path = os.path.join(label_dir, audio_file)\n",
    "                        self.files.append(audio_file_path)\n",
    "                        self.labels.append(label)\n",
    "\n",
    "        #One-hot encode string labels as tensors\n",
    "        le = LabelEncoder()\n",
    "        self.encoded_labels = le.fit_transform(self.labels)\n",
    "        self.encoded_labels = torch.from_numpy(self.encoded_labels)\n",
    "        # self.encoded_labels = torch.nn.functional.one_hot(self.encoded_labels)\n",
    "        \n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        audio_path = self.files[idx]\n",
    "        label = self.encoded_labels[idx]\n",
    "        #Extract MFCC data from audio\n",
    "        waveform, audio_sample_rate = torchaudio.load(audio_path)\n",
    "        \n",
    "\n",
    "        #Some files are mono (1 channel), duplicate channel if so\n",
    "        if waveform.shape[0] == 1:\n",
    "            waveform = waveform.repeat(2,1)\n",
    "  \n",
    "        waveform_MFCC = self.transform(waveform)\n",
    "\n",
    "        #Input shapes need to be the same, take the average coefficient over time intervals, should output a tensor of shape (2, n_mfcc)\n",
    "        waveform_MFCC = torch.mean(waveform_MFCC, dim=2)\n",
    "        \n",
    "        return waveform_MFCC, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8e19ec48-bf82-4ff9-879f-29478772543f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "train_dir = os.path.join(data_path, \"Train\")\n",
    "test_dir = os.path.join(data_path, \"Test\")\n",
    "\n",
    "# Create instances of custom dataset\n",
    "train_dataset = WAVDataset(data_dir=train_dir, audio_sample_rate=16000)\n",
    "test_dataset = WAVDataset(data_dir=test_dir, audio_sample_rate=16000)\n",
    "\n",
    "# Create DataLoaders\n",
    "data_batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=data_batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=data_batch_size, shuffle=False)\n",
    "\n",
    "# for batch_data, batch_labels in train_loader:\n",
    "#     print(\"Batch Data Shape:\", batch_data.shape)  # Shape: (batch_size, 13)\n",
    "#     print(\"Batch Labels Shape:\", batch_labels.shape)  # Shape: (batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "036ea6f8-d34d-409d-bbea-701552c4916e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChordClassifier(\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=80, out_features=128, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.3, inplace=False)\n",
      "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Dropout(p=0.3, inplace=False)\n",
      "    (7): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (8): ReLU()\n",
      "    (9): Dropout(p=0.3, inplace=False)\n",
      "    (10): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (11): ReLU()\n",
      "    (12): Dropout(p=0.2, inplace=False)\n",
      "    (13): Linear(in_features=16, out_features=8, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Set GPU or CPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "class ChordClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(40*2, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(16, 8),\n",
    "            # nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "    \n",
    "    # 3. Define a forward method containing the forward pass computation\n",
    "    def forward(self, x):\n",
    "        x = self.linear_relu_stack(x)\n",
    "        return x\n",
    "\n",
    "# 4. Create an instance of the model and send it to target device\n",
    "model = ChordClassifier().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b2d29ffe-3d34-4e6e-9658-b42e82e9ffdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 5 loss: 0.011708209753036498 accuracy 9.375\n",
      "  batch 10 loss: 0.010815365076065063 accuracy 12.8125\n",
      "  batch 15 loss: 0.010855023622512817 accuracy 12.708333333333334\n",
      "  batch 20 loss: 0.010578906059265137 accuracy 12.34375\n",
      "  batch 25 loss: 0.01038986086845398 accuracy 12.25\n",
      "  batch 30 loss: 0.010525167465209961 accuracy 13.020833333333334\n",
      "  batch 35 loss: 0.010701079607009887 accuracy 12.5\n",
      "  batch 40 loss: 0.010523247957229614 accuracy 12.65625\n",
      "  batch 5 loss: 0.018978142499923707 accuracy 15.625\n",
      "  batch 10 loss: 0.01038432240486145 accuracy 15.0\n",
      "  batch 15 loss: 0.010512538194656373 accuracy 13.541666666666666\n",
      "  batch 20 loss: 0.010400304794311524 accuracy 13.4375\n",
      "  batch 25 loss: 0.010244907379150391 accuracy 13.75\n",
      "  batch 30 loss: 0.010374575853347778 accuracy 13.958333333333334\n",
      "  batch 35 loss: 0.010480214834213257 accuracy 13.928571428571429\n",
      "  batch 40 loss: 0.010245428800582886 accuracy 14.0625\n",
      "  batch 5 loss: 0.018835041999816896 accuracy 12.5\n",
      "  batch 10 loss: 0.010461587429046631 accuracy 10.9375\n",
      "  batch 15 loss: 0.010195410966873169 accuracy 11.25\n",
      "  batch 20 loss: 0.010192127466201783 accuracy 12.34375\n",
      "  batch 25 loss: 0.010357726216316223 accuracy 13.25\n",
      "  batch 30 loss: 0.010331692695617676 accuracy 13.4375\n",
      "  batch 35 loss: 0.010476360082626342 accuracy 12.678571428571429\n",
      "  batch 40 loss: 0.010250200033187867 accuracy 13.046875\n",
      "  batch 5 loss: 0.018403961181640626 accuracy 17.5\n",
      "  batch 10 loss: 0.010422644138336181 accuracy 16.25\n",
      "  batch 15 loss: 0.010322450399398804 accuracy 17.083333333333332\n",
      "  batch 20 loss: 0.010352121829986573 accuracy 17.34375\n",
      "  batch 25 loss: 0.010149322032928466 accuracy 17.875\n",
      "  batch 30 loss: 0.009760226011276246 accuracy 18.4375\n",
      "  batch 35 loss: 0.009893203139305114 accuracy 18.928571428571427\n",
      "  batch 40 loss: 0.010306142091751099 accuracy 18.828125\n",
      "  batch 5 loss: 0.017936186194419862 accuracy 16.875\n",
      "  batch 10 loss: 0.010006658673286439 accuracy 15.9375\n",
      "  batch 15 loss: 0.010032013297080993 accuracy 15.208333333333334\n",
      "  batch 20 loss: 0.009691121459007263 accuracy 15.9375\n",
      "  batch 25 loss: 0.009565524935722351 accuracy 17.25\n",
      "  batch 30 loss: 0.009683636546134949 accuracy 17.395833333333332\n",
      "  batch 35 loss: 0.009451696634292602 accuracy 17.857142857142858\n",
      "  batch 40 loss: 0.009718763351440429 accuracy 18.28125\n",
      "  batch 5 loss: 0.016622944474220275 accuracy 27.5\n",
      "  batch 10 loss: 0.009613428354263306 accuracy 24.6875\n",
      "  batch 15 loss: 0.008895411014556884 accuracy 25.416666666666668\n",
      "  batch 20 loss: 0.009473867416381836 accuracy 24.375\n",
      "  batch 25 loss: 0.009081090807914733 accuracy 24.5\n",
      "  batch 30 loss: 0.009222452163696288 accuracy 24.375\n",
      "  batch 35 loss: 0.009008919477462768 accuracy 24.732142857142858\n",
      "  batch 40 loss: 0.009003231525421143 accuracy 24.375\n",
      "  batch 5 loss: 0.016301245331764223 accuracy 30.0\n",
      "  batch 10 loss: 0.009284618258476257 accuracy 27.5\n",
      "  batch 15 loss: 0.009062978625297546 accuracy 26.875\n",
      "  batch 20 loss: 0.00877181613445282 accuracy 27.96875\n",
      "  batch 25 loss: 0.008790408492088318 accuracy 29.125\n",
      "  batch 30 loss: 0.008509180188179016 accuracy 29.270833333333332\n",
      "  batch 35 loss: 0.007889357686042786 accuracy 30.535714285714285\n",
      "  batch 40 loss: 0.008864846587181091 accuracy 30.46875\n",
      "  batch 5 loss: 0.01462289834022522 accuracy 31.875\n",
      "  batch 10 loss: 0.008615602850914 accuracy 28.4375\n",
      "  batch 15 loss: 0.008092292428016663 accuracy 29.375\n",
      "  batch 20 loss: 0.008493877172470092 accuracy 28.90625\n",
      "  batch 25 loss: 0.008353428244590759 accuracy 28.375\n",
      "  batch 30 loss: 0.0077807832956314086 accuracy 30.0\n",
      "  batch 35 loss: 0.008040801882743835 accuracy 29.821428571428573\n",
      "  batch 40 loss: 0.00807646346092224 accuracy 30.46875\n",
      "  batch 5 loss: 0.014280786275863648 accuracy 32.5\n",
      "  batch 10 loss: 0.007943457484245301 accuracy 34.0625\n",
      "  batch 15 loss: 0.007797585844993592 accuracy 34.583333333333336\n",
      "  batch 20 loss: 0.007560927033424377 accuracy 34.84375\n",
      "  batch 25 loss: 0.00774225664138794 accuracy 35.125\n",
      "  batch 30 loss: 0.007642431735992432 accuracy 35.833333333333336\n",
      "  batch 35 loss: 0.007884623289108276 accuracy 35.982142857142854\n",
      "  batch 40 loss: 0.007854557514190674 accuracy 35.546875\n",
      "  batch 5 loss: 0.013391362309455871 accuracy 41.875\n",
      "  batch 10 loss: 0.007242644309997558 accuracy 44.0625\n",
      "  batch 15 loss: 0.007555036067962646 accuracy 42.083333333333336\n",
      "  batch 20 loss: 0.0076006602048873904 accuracy 42.96875\n",
      "  batch 25 loss: 0.007213421583175659 accuracy 43.75\n",
      "  batch 30 loss: 0.00800810706615448 accuracy 41.979166666666664\n",
      "  batch 35 loss: 0.00718931245803833 accuracy 41.160714285714285\n",
      "  batch 40 loss: 0.006842826247215271 accuracy 41.015625\n",
      "  batch 5 loss: 0.013579552054405213 accuracy 40.0\n",
      "  batch 10 loss: 0.007307887196540832 accuracy 40.3125\n",
      "  batch 15 loss: 0.006885736584663391 accuracy 42.5\n",
      "  batch 20 loss: 0.006965011715888977 accuracy 43.28125\n",
      "  batch 25 loss: 0.007634753346443176 accuracy 42.25\n",
      "  batch 30 loss: 0.006530761599540711 accuracy 43.229166666666664\n",
      "  batch 35 loss: 0.007133605360984802 accuracy 42.67857142857143\n",
      "  batch 40 loss: 0.007033596634864807 accuracy 42.96875\n",
      "  batch 5 loss: 0.012187330842018127 accuracy 45.625\n",
      "  batch 10 loss: 0.007021019458770752 accuracy 47.1875\n",
      "  batch 15 loss: 0.006572854638099671 accuracy 47.5\n",
      "  batch 20 loss: 0.006162736415863037 accuracy 47.96875\n",
      "  batch 25 loss: 0.00690426504611969 accuracy 47.125\n",
      "  batch 30 loss: 0.006639255404472351 accuracy 47.5\n",
      "  batch 35 loss: 0.006478820323944092 accuracy 47.32142857142857\n",
      "  batch 40 loss: 0.0068615999221801754 accuracy 47.1875\n",
      "  batch 5 loss: 0.011817062020301819 accuracy 51.25\n",
      "  batch 10 loss: 0.006450297951698303 accuracy 49.375\n",
      "  batch 15 loss: 0.00597569489479065 accuracy 50.625\n",
      "  batch 20 loss: 0.006769393324851989 accuracy 50.3125\n",
      "  batch 25 loss: 0.007009315967559815 accuracy 48.0\n",
      "  batch 30 loss: 0.006509762048721313 accuracy 48.645833333333336\n",
      "  batch 35 loss: 0.006954257249832153 accuracy 48.214285714285715\n",
      "  batch 40 loss: 0.006615035772323609 accuracy 48.28125\n",
      "  batch 5 loss: 0.011203836262226105 accuracy 49.375\n",
      "  batch 10 loss: 0.0065913920402526855 accuracy 49.375\n",
      "  batch 15 loss: 0.006433121085166931 accuracy 49.583333333333336\n",
      "  batch 20 loss: 0.006314892172813415 accuracy 48.4375\n",
      "  batch 25 loss: 0.005630319237709045 accuracy 50.5\n",
      "  batch 30 loss: 0.006158152878284454 accuracy 50.0\n",
      "  batch 35 loss: 0.006079066872596741 accuracy 50.892857142857146\n",
      "  batch 40 loss: 0.006690274834632874 accuracy 50.390625\n",
      "  batch 5 loss: 0.010364486992359161 accuracy 56.875\n",
      "  batch 10 loss: 0.006051106333732605 accuracy 54.0625\n",
      "  batch 15 loss: 0.006433004498481751 accuracy 53.333333333333336\n",
      "  batch 20 loss: 0.005976919412612915 accuracy 53.90625\n",
      "  batch 25 loss: 0.006167617082595825 accuracy 53.375\n",
      "  batch 30 loss: 0.006661934375762939 accuracy 52.8125\n",
      "  batch 35 loss: 0.005475682199001312 accuracy 53.035714285714285\n",
      "  batch 40 loss: 0.006193024158477783 accuracy 52.34375\n",
      "  batch 5 loss: 0.010001950144767761 accuracy 58.75\n",
      "  batch 10 loss: 0.005904582023620606 accuracy 57.5\n",
      "  batch 15 loss: 0.005947829723358155 accuracy 56.458333333333336\n",
      "  batch 20 loss: 0.005620657563209534 accuracy 56.09375\n",
      "  batch 25 loss: 0.005806989431381225 accuracy 55.75\n",
      "  batch 30 loss: 0.006076471209526062 accuracy 54.583333333333336\n",
      "  batch 35 loss: 0.006192021310329437 accuracy 54.19642857142857\n",
      "  batch 40 loss: 0.006530657052993775 accuracy 53.4375\n",
      "  batch 5 loss: 0.010309362113475799 accuracy 51.25\n",
      "  batch 10 loss: 0.005568695366382599 accuracy 55.9375\n",
      "  batch 15 loss: 0.005890452623367309 accuracy 54.583333333333336\n",
      "  batch 20 loss: 0.006144765615463257 accuracy 54.21875\n",
      "  batch 25 loss: 0.005473012626171112 accuracy 55.25\n",
      "  batch 30 loss: 0.005421326756477356 accuracy 55.416666666666664\n",
      "  batch 35 loss: 0.005614180862903595 accuracy 55.17857142857143\n",
      "  batch 40 loss: 0.005491342544555664 accuracy 54.765625\n",
      "  batch 5 loss: 0.009957703292369842 accuracy 56.25\n",
      "  batch 10 loss: 0.005952674388885498 accuracy 55.3125\n",
      "  batch 15 loss: 0.005179539144039154 accuracy 56.458333333333336\n",
      "  batch 20 loss: 0.0057795166969299315 accuracy 55.9375\n",
      "  batch 25 loss: 0.004678885459899903 accuracy 57.75\n",
      "  batch 30 loss: 0.004927788197994232 accuracy 57.8125\n",
      "  batch 35 loss: 0.005401509404182434 accuracy 58.035714285714285\n",
      "  batch 40 loss: 0.005497392177581787 accuracy 58.203125\n",
      "  batch 5 loss: 0.01053385478258133 accuracy 50.0\n",
      "  batch 10 loss: 0.005291037917137146 accuracy 52.1875\n",
      "  batch 15 loss: 0.005530207455158234 accuracy 53.125\n",
      "  batch 20 loss: 0.005673055589199066 accuracy 53.90625\n",
      "  batch 25 loss: 0.004767720758914948 accuracy 55.5\n",
      "  batch 30 loss: 0.005020484209060669 accuracy 55.520833333333336\n",
      "  batch 35 loss: 0.004911909699440002 accuracy 56.875\n",
      "  batch 40 loss: 0.005158056735992431 accuracy 57.109375\n",
      "  batch 5 loss: 0.00930991107225418 accuracy 64.375\n",
      "  batch 10 loss: 0.005574439764022827 accuracy 58.4375\n",
      "  batch 15 loss: 0.005175985872745514 accuracy 58.958333333333336\n",
      "  batch 20 loss: 0.005680068969726563 accuracy 58.28125\n",
      "  batch 25 loss: 0.00493375027179718 accuracy 58.5\n",
      "  batch 30 loss: 0.004918646812438965 accuracy 59.270833333333336\n",
      "  batch 35 loss: 0.005492333114147186 accuracy 59.19642857142857\n",
      "  batch 40 loss: 0.0056964998245239255 accuracy 58.59375\n",
      "  batch 5 loss: 0.009257698237895965 accuracy 60.0\n",
      "  batch 10 loss: 0.004738095700740814 accuracy 61.25\n",
      "  batch 15 loss: 0.004858152866363525 accuracy 60.208333333333336\n",
      "  batch 20 loss: 0.004924041271209717 accuracy 60.46875\n",
      "  batch 25 loss: 0.00523047149181366 accuracy 59.125\n",
      "  batch 30 loss: 0.00500137335062027 accuracy 59.375\n",
      "  batch 35 loss: 0.004364843428134918 accuracy 60.535714285714285\n",
      "  batch 40 loss: 0.004893100380897522 accuracy 60.46875\n",
      "  batch 5 loss: 0.008734491527080536 accuracy 64.375\n",
      "  batch 10 loss: 0.004461625099182129 accuracy 66.875\n",
      "  batch 15 loss: 0.004527487576007843 accuracy 65.83333333333333\n",
      "  batch 20 loss: 0.005574477076530457 accuracy 63.59375\n",
      "  batch 25 loss: 0.005156455874443054 accuracy 62.375\n",
      "  batch 30 loss: 0.004515003442764282 accuracy 62.708333333333336\n",
      "  batch 35 loss: 0.004445991575717926 accuracy 62.767857142857146\n",
      "  batch 40 loss: 0.00553098315000534 accuracy 61.953125\n",
      "  batch 5 loss: 0.007912206470966339 accuracy 68.125\n",
      "  batch 10 loss: 0.005336836099624633 accuracy 63.4375\n",
      "  batch 15 loss: 0.004274191081523895 accuracy 63.333333333333336\n",
      "  batch 20 loss: 0.005260956764221191 accuracy 61.875\n",
      "  batch 25 loss: 0.005294985890388489 accuracy 60.875\n",
      "  batch 30 loss: 0.0044533913731575015 accuracy 61.354166666666664\n",
      "  batch 35 loss: 0.005447580575942993 accuracy 60.982142857142854\n",
      "  batch 40 loss: 0.004950405836105347 accuracy 60.859375\n",
      "  batch 5 loss: 0.008318422138690948 accuracy 64.375\n",
      "  batch 10 loss: 0.004655396521091461 accuracy 65.9375\n",
      "  batch 15 loss: 0.004683694660663605 accuracy 65.625\n",
      "  batch 20 loss: 0.005117398500442505 accuracy 64.6875\n",
      "  batch 25 loss: 0.00491174978017807 accuracy 64.875\n",
      "  batch 30 loss: 0.005126347541809082 accuracy 64.47916666666667\n",
      "  batch 35 loss: 0.004407284319400787 accuracy 64.73214285714286\n",
      "  batch 40 loss: 0.004817539513111114 accuracy 64.375\n",
      "  batch 5 loss: 0.007665814876556397 accuracy 65.625\n",
      "  batch 10 loss: 0.004903831958770752 accuracy 64.375\n",
      "  batch 15 loss: 0.004784087359905243 accuracy 63.541666666666664\n",
      "  batch 20 loss: 0.004828275084495544 accuracy 64.21875\n",
      "  batch 25 loss: 0.004712739050388336 accuracy 64.0\n",
      "  batch 30 loss: 0.005308912634849549 accuracy 62.916666666666664\n",
      "  batch 35 loss: 0.005323327422142029 accuracy 61.964285714285715\n",
      "  batch 40 loss: 0.004707895576953888 accuracy 62.265625\n",
      "  batch 5 loss: 0.007993858814239502 accuracy 65.625\n",
      "  batch 10 loss: 0.0050798959136009215 accuracy 62.5\n",
      "  batch 15 loss: 0.004586222887039184 accuracy 62.708333333333336\n",
      "  batch 20 loss: 0.00410795122385025 accuracy 63.59375\n",
      "  batch 25 loss: 0.004704970836639405 accuracy 63.5\n",
      "  batch 30 loss: 0.005277279853820801 accuracy 62.604166666666664\n",
      "  batch 35 loss: 0.0041485862135887145 accuracy 63.214285714285715\n",
      "  batch 40 loss: 0.004210894703865051 accuracy 64.21875\n",
      "  batch 5 loss: 0.008633675456047058 accuracy 63.75\n",
      "  batch 10 loss: 0.004564990043640136 accuracy 66.5625\n",
      "  batch 15 loss: 0.004240389049053192 accuracy 66.25\n",
      "  batch 20 loss: 0.00404931378364563 accuracy 67.34375\n",
      "  batch 25 loss: 0.004262469828128814 accuracy 67.0\n",
      "  batch 30 loss: 0.004343472182750702 accuracy 66.77083333333333\n",
      "  batch 35 loss: 0.004216886639595032 accuracy 66.78571428571429\n",
      "  batch 40 loss: 0.004422060132026672 accuracy 67.03125\n",
      "  batch 5 loss: 0.008613470315933227 accuracy 67.5\n",
      "  batch 10 loss: 0.004545824408531189 accuracy 65.625\n",
      "  batch 15 loss: 0.0044431047439575195 accuracy 66.45833333333333\n",
      "  batch 20 loss: 0.00426819109916687 accuracy 67.03125\n",
      "  batch 25 loss: 0.0037842671871185303 accuracy 67.25\n",
      "  batch 30 loss: 0.0052980054616928104 accuracy 66.04166666666667\n",
      "  batch 35 loss: 0.004699675321578979 accuracy 65.71428571428571\n",
      "  batch 40 loss: 0.004196314632892609 accuracy 65.78125\n",
      "  batch 5 loss: 0.007779431164264679 accuracy 66.25\n",
      "  batch 10 loss: 0.004026552677154541 accuracy 68.125\n",
      "  batch 15 loss: 0.0056762673854827885 accuracy 65.625\n",
      "  batch 20 loss: 0.003916595041751862 accuracy 67.65625\n",
      "  batch 25 loss: 0.004276359319686889 accuracy 67.375\n",
      "  batch 30 loss: 0.003530710220336914 accuracy 68.33333333333333\n",
      "  batch 35 loss: 0.004895649671554566 accuracy 67.14285714285714\n",
      "  batch 40 loss: 0.004820658147335052 accuracy 66.171875\n",
      "  batch 5 loss: 0.0077077471017837525 accuracy 67.5\n",
      "  batch 10 loss: 0.004413795411586761 accuracy 65.625\n",
      "  batch 15 loss: 0.004525273203849793 accuracy 65.83333333333333\n",
      "  batch 20 loss: 0.004012981593608856 accuracy 67.03125\n",
      "  batch 25 loss: 0.004383424699306488 accuracy 67.75\n",
      "  batch 30 loss: 0.004794463455677032 accuracy 67.1875\n",
      "  batch 35 loss: 0.004691368520259857 accuracy 66.42857142857143\n",
      "  batch 40 loss: 0.004194540560245514 accuracy 66.484375\n",
      "  batch 5 loss: 0.0078584885597229 accuracy 65.0\n",
      "  batch 10 loss: 0.003727448493242264 accuracy 67.8125\n",
      "  batch 15 loss: 0.004162020742893219 accuracy 67.5\n",
      "  batch 20 loss: 0.0037316714525222777 accuracy 68.59375\n",
      "  batch 25 loss: 0.0040451021194458005 accuracy 68.75\n",
      "  batch 30 loss: 0.003214085787534714 accuracy 70.0\n",
      "  batch 35 loss: 0.004747000098228454 accuracy 69.73214285714286\n",
      "  batch 40 loss: 0.00425648158788681 accuracy 69.609375\n",
      "  batch 5 loss: 0.008627020299434662 accuracy 61.25\n",
      "  batch 10 loss: 0.003545149624347687 accuracy 68.125\n",
      "  batch 15 loss: 0.004785284280776978 accuracy 68.125\n",
      "  batch 20 loss: 0.0038097639083862307 accuracy 69.6875\n",
      "  batch 25 loss: 0.003721620202064514 accuracy 70.375\n",
      "  batch 30 loss: 0.0038579317331314087 accuracy 70.41666666666667\n",
      "  batch 35 loss: 0.004148584306240082 accuracy 70.26785714285714\n",
      "  batch 40 loss: 0.004497487366199493 accuracy 70.15625\n",
      "  batch 5 loss: 0.007581766605377197 accuracy 68.125\n",
      "  batch 10 loss: 0.003780978500843048 accuracy 68.4375\n",
      "  batch 15 loss: 0.004251043200492859 accuracy 67.91666666666667\n",
      "  batch 20 loss: 0.0043653671145439145 accuracy 67.03125\n",
      "  batch 25 loss: 0.0039858858585357666 accuracy 67.0\n",
      "  batch 30 loss: 0.004044950544834137 accuracy 67.60416666666667\n",
      "  batch 35 loss: 0.0038121950030326843 accuracy 68.30357142857143\n",
      "  batch 40 loss: 0.004576864838600159 accuracy 68.59375\n",
      "  batch 5 loss: 0.007166042625904083 accuracy 69.375\n",
      "  batch 10 loss: 0.003908828020095825 accuracy 69.6875\n",
      "  batch 15 loss: 0.004204781770706177 accuracy 69.375\n",
      "  batch 20 loss: 0.0037910786867141723 accuracy 69.84375\n",
      "  batch 25 loss: 0.0040123051404953 accuracy 70.25\n",
      "  batch 30 loss: 0.004254720747470856 accuracy 70.625\n",
      "  batch 35 loss: 0.003997689545154571 accuracy 70.17857142857143\n",
      "  batch 40 loss: 0.0033431500494480134 accuracy 71.328125\n",
      "  batch 5 loss: 0.006704851388931275 accuracy 75.0\n",
      "  batch 10 loss: 0.004200159847736359 accuracy 72.8125\n",
      "  batch 15 loss: 0.0038150941133499147 accuracy 71.875\n",
      "  batch 20 loss: 0.0035897093415260314 accuracy 73.125\n",
      "  batch 25 loss: 0.0037424619197845457 accuracy 72.875\n",
      "  batch 30 loss: 0.004568634748458862 accuracy 72.08333333333333\n",
      "  batch 35 loss: 0.004610360264778137 accuracy 71.16071428571429\n",
      "  batch 40 loss: 0.004170071005821228 accuracy 71.171875\n",
      "  batch 5 loss: 0.0068781026005744934 accuracy 71.25\n",
      "  batch 10 loss: 0.004653817236423492 accuracy 66.875\n",
      "  batch 15 loss: 0.004117523312568664 accuracy 67.5\n",
      "  batch 20 loss: 0.004164685904979706 accuracy 67.65625\n",
      "  batch 25 loss: 0.004265374302864075 accuracy 67.75\n",
      "  batch 30 loss: 0.005224123001098633 accuracy 66.875\n",
      "  batch 35 loss: 0.004057988047599792 accuracy 67.32142857142857\n",
      "  batch 40 loss: 0.0037636756896972656 accuracy 67.8125\n",
      "  batch 5 loss: 0.007591954708099365 accuracy 67.5\n",
      "  batch 10 loss: 0.0038222376108169556 accuracy 70.0\n",
      "  batch 15 loss: 0.0038437846302986143 accuracy 71.66666666666667\n",
      "  batch 20 loss: 0.003561553418636322 accuracy 71.71875\n",
      "  batch 25 loss: 0.004236551523208618 accuracy 70.875\n",
      "  batch 30 loss: 0.004096668183803559 accuracy 70.20833333333333\n",
      "  batch 35 loss: 0.004083511471748352 accuracy 69.82142857142857\n",
      "  batch 40 loss: 0.0030324522852897646 accuracy 70.625\n",
      "  batch 5 loss: 0.007126692473888397 accuracy 71.25\n",
      "  batch 10 loss: 0.0039587743878364565 accuracy 69.6875\n",
      "  batch 15 loss: 0.003793834388256073 accuracy 70.625\n",
      "  batch 20 loss: 0.0033645185232162476 accuracy 71.5625\n",
      "  batch 25 loss: 0.003973747789859772 accuracy 71.625\n",
      "  batch 30 loss: 0.003726374328136444 accuracy 71.875\n",
      "  batch 35 loss: 0.004446771800518036 accuracy 71.16071428571429\n",
      "  batch 40 loss: 0.0037447457015514374 accuracy 71.25\n",
      "  batch 5 loss: 0.007501813113689423 accuracy 66.875\n",
      "  batch 10 loss: 0.0034240079522132876 accuracy 71.25\n",
      "  batch 15 loss: 0.0033956882655620576 accuracy 73.54166666666667\n",
      "  batch 20 loss: 0.003550328552722931 accuracy 73.59375\n",
      "  batch 25 loss: 0.0034560571312904358 accuracy 73.875\n",
      "  batch 30 loss: 0.003634998768568039 accuracy 73.75\n",
      "  batch 35 loss: 0.0036785374283790587 accuracy 73.75\n",
      "  batch 40 loss: 0.0032731703817844393 accuracy 74.0625\n",
      "  batch 5 loss: 0.006969781130552292 accuracy 68.125\n",
      "  batch 10 loss: 0.0037223467230796813 accuracy 70.3125\n",
      "  batch 15 loss: 0.0033424324095249177 accuracy 71.875\n",
      "  batch 20 loss: 0.003220516711473465 accuracy 72.8125\n",
      "  batch 25 loss: 0.004090148508548736 accuracy 72.875\n",
      "  batch 30 loss: 0.0032095655500888826 accuracy 73.54166666666667\n",
      "  batch 35 loss: 0.003921764433383942 accuracy 73.48214285714286\n",
      "  batch 40 loss: 0.004928190529346466 accuracy 72.109375\n",
      "  batch 5 loss: 0.007260797291994095 accuracy 73.75\n",
      "  batch 10 loss: 0.0028107278943061828 accuracy 76.875\n",
      "  batch 15 loss: 0.003373072862625122 accuracy 75.83333333333333\n",
      "  batch 20 loss: 0.0035720024704933165 accuracy 74.21875\n",
      "  batch 25 loss: 0.003824871599674225 accuracy 73.875\n",
      "  batch 30 loss: 0.0037531835436820983 accuracy 73.75\n",
      "  batch 35 loss: 0.0036920856237411498 accuracy 73.57142857142857\n",
      "  batch 40 loss: 0.0038673332929611208 accuracy 73.046875\n",
      "  batch 5 loss: 0.007558623135089875 accuracy 68.125\n",
      "  batch 10 loss: 0.0034555306136608123 accuracy 71.5625\n",
      "  batch 15 loss: 0.003663841962814331 accuracy 72.29166666666667\n",
      "  batch 20 loss: 0.003572620093822479 accuracy 73.125\n",
      "  batch 25 loss: 0.0043304004073143 accuracy 72.375\n",
      "  batch 30 loss: 0.003828530490398407 accuracy 72.60416666666667\n",
      "  batch 35 loss: 0.004013785302639007 accuracy 72.32142857142857\n",
      "  batch 40 loss: 0.003249580681324005 accuracy 72.734375\n",
      "  batch 5 loss: 0.006536330223083496 accuracy 75.625\n",
      "  batch 10 loss: 0.0036026164591312407 accuracy 72.8125\n",
      "  batch 15 loss: 0.00386204993724823 accuracy 73.125\n",
      "  batch 20 loss: 0.0035754369497299193 accuracy 73.125\n",
      "  batch 25 loss: 0.003362419009208679 accuracy 73.625\n",
      "  batch 30 loss: 0.003708562910556793 accuracy 73.22916666666667\n",
      "  batch 35 loss: 0.0036823166012763977 accuracy 73.125\n",
      "  batch 40 loss: 0.003941831767559052 accuracy 72.65625\n",
      "  batch 5 loss: 0.005819704920053482 accuracy 73.75\n",
      "  batch 10 loss: 0.0028725233972072602 accuracy 76.25\n",
      "  batch 15 loss: 0.00335759437084198 accuracy 76.04166666666667\n",
      "  batch 20 loss: 0.003936439275741577 accuracy 75.0\n",
      "  batch 25 loss: 0.004090551137924194 accuracy 74.0\n",
      "  batch 30 loss: 0.0031581804752349855 accuracy 74.0625\n",
      "  batch 35 loss: 0.0032318761944770814 accuracy 74.73214285714286\n",
      "  batch 40 loss: 0.003793244421482086 accuracy 74.453125\n",
      "  batch 5 loss: 0.0066244639456272125 accuracy 72.5\n",
      "  batch 10 loss: 0.004208631455898285 accuracy 69.6875\n",
      "  batch 15 loss: 0.0028798614740371702 accuracy 71.66666666666667\n",
      "  batch 20 loss: 0.003356410622596741 accuracy 72.5\n",
      "  batch 25 loss: 0.0031546433568000794 accuracy 73.75\n",
      "  batch 30 loss: 0.003761755108833313 accuracy 73.85416666666667\n",
      "  batch 35 loss: 0.0027513098269701004 accuracy 74.82142857142857\n",
      "  batch 40 loss: 0.003938501894474029 accuracy 74.140625\n",
      "  batch 5 loss: 0.006248480051755905 accuracy 71.25\n",
      "  batch 10 loss: 0.0031689723134040834 accuracy 73.4375\n",
      "  batch 15 loss: 0.003825113892555237 accuracy 72.29166666666667\n",
      "  batch 20 loss: 0.0033191164135932924 accuracy 73.28125\n",
      "  batch 25 loss: 0.00403088229894638 accuracy 71.875\n",
      "  batch 30 loss: 0.0033994494676589967 accuracy 72.91666666666667\n",
      "  batch 35 loss: 0.0037671042680740355 accuracy 72.41071428571429\n",
      "  batch 40 loss: 0.003576339304447174 accuracy 73.046875\n",
      "  batch 5 loss: 0.0074802936911582945 accuracy 61.875\n",
      "  batch 10 loss: 0.0033983272314071656 accuracy 70.0\n",
      "  batch 15 loss: 0.0034198455810546874 accuracy 71.875\n",
      "  batch 20 loss: 0.003382068783044815 accuracy 72.65625\n",
      "  batch 25 loss: 0.0037976136803627015 accuracy 73.0\n",
      "  batch 30 loss: 0.0035227484703063963 accuracy 73.125\n",
      "  batch 35 loss: 0.002813491642475128 accuracy 73.75\n",
      "  batch 40 loss: 0.003613786220550537 accuracy 73.828125\n",
      "  batch 5 loss: 0.005532333672046662 accuracy 75.625\n",
      "  batch 10 loss: 0.0031966773271560668 accuracy 77.5\n",
      "  batch 15 loss: 0.00364367738366127 accuracy 77.29166666666667\n",
      "  batch 20 loss: 0.004309853255748749 accuracy 75.0\n",
      "  batch 25 loss: 0.0036432448029518126 accuracy 75.125\n",
      "  batch 30 loss: 0.0033359402418136597 accuracy 75.0\n",
      "  batch 35 loss: 0.0034345598816871645 accuracy 75.08928571428571\n",
      "  batch 40 loss: 0.0032133859395980834 accuracy 75.15625\n",
      "  batch 5 loss: 0.006255648165941238 accuracy 74.375\n",
      "  batch 10 loss: 0.0030492634177207946 accuracy 77.5\n",
      "  batch 15 loss: 0.002927515208721161 accuracy 77.08333333333333\n",
      "  batch 20 loss: 0.003118973582983017 accuracy 76.5625\n",
      "  batch 25 loss: 0.00420508998632431 accuracy 75.0\n",
      "  batch 30 loss: 0.003843201696872711 accuracy 74.58333333333333\n",
      "  batch 35 loss: 0.004155892848968506 accuracy 74.46428571428571\n",
      "  batch 40 loss: 0.0035330806970596314 accuracy 74.140625\n",
      "  batch 5 loss: 0.006599782288074493 accuracy 74.375\n",
      "  batch 10 loss: 0.0031584572792053224 accuracy 74.375\n",
      "  batch 15 loss: 0.0037754055857658385 accuracy 73.75\n",
      "  batch 20 loss: 0.0037166334986686706 accuracy 74.0625\n",
      "  batch 25 loss: 0.0034332313537597655 accuracy 74.0\n",
      "  batch 30 loss: 0.00341409033536911 accuracy 73.95833333333333\n",
      "  batch 35 loss: 0.003068910539150238 accuracy 74.375\n",
      "  batch 40 loss: 0.003124574512243271 accuracy 74.921875\n",
      "  batch 5 loss: 0.005888861030340194 accuracy 75.0\n",
      "  batch 10 loss: 0.0034554532766342162 accuracy 74.6875\n",
      "  batch 15 loss: 0.00304558128118515 accuracy 76.04166666666667\n",
      "  batch 20 loss: 0.0033981890082359313 accuracy 75.15625\n",
      "  batch 25 loss: 0.003284593880176544 accuracy 75.0\n",
      "  batch 30 loss: 0.003196191906929016 accuracy 74.58333333333333\n",
      "  batch 35 loss: 0.004524069249629974 accuracy 73.92857142857143\n",
      "  batch 40 loss: 0.002577654182910919 accuracy 74.921875\n",
      "  batch 5 loss: 0.006968878626823425 accuracy 70.625\n",
      "  batch 10 loss: 0.0032509475648403166 accuracy 73.75\n",
      "  batch 15 loss: 0.003452745258808136 accuracy 74.79166666666667\n",
      "  batch 20 loss: 0.003254988968372345 accuracy 75.78125\n",
      "  batch 25 loss: 0.0029041708409786224 accuracy 76.75\n",
      "  batch 30 loss: 0.003353444665670395 accuracy 76.77083333333333\n",
      "  batch 35 loss: 0.0029926802814006807 accuracy 76.51785714285714\n",
      "  batch 40 loss: 0.003672796905040741 accuracy 76.171875\n",
      "  batch 5 loss: 0.0060060123503208164 accuracy 71.25\n",
      "  batch 10 loss: 0.003622735470533371 accuracy 71.875\n",
      "  batch 15 loss: 0.0035076020658016205 accuracy 71.875\n",
      "  batch 20 loss: 0.0026307390928268434 accuracy 74.0625\n",
      "  batch 25 loss: 0.0031478317975997924 accuracy 74.75\n",
      "  batch 30 loss: 0.0039169974327087406 accuracy 74.27083333333333\n",
      "  batch 35 loss: 0.003635470598936081 accuracy 74.64285714285714\n",
      "  batch 40 loss: 0.00372342449426651 accuracy 74.375\n",
      "  batch 5 loss: 0.005192391812801361 accuracy 78.75\n",
      "  batch 10 loss: 0.0028781306743621824 accuracy 80.0\n",
      "  batch 15 loss: 0.0032939926385879515 accuracy 78.125\n",
      "  batch 20 loss: 0.0036379951238632202 accuracy 77.5\n",
      "  batch 25 loss: 0.003782926917076111 accuracy 76.25\n",
      "  batch 30 loss: 0.004154658257961273 accuracy 75.20833333333333\n",
      "  batch 35 loss: 0.003123059630393982 accuracy 75.35714285714286\n",
      "  batch 40 loss: 0.0030383150577545166 accuracy 75.9375\n",
      "  batch 5 loss: 0.006170445144176483 accuracy 76.875\n",
      "  batch 10 loss: 0.0028219980597496033 accuracy 76.875\n",
      "  batch 15 loss: 0.0037583572268486023 accuracy 76.25\n",
      "  batch 20 loss: 0.00327687081694603 accuracy 75.9375\n",
      "  batch 25 loss: 0.0028912812173366546 accuracy 76.625\n",
      "  batch 30 loss: 0.0034031333327293398 accuracy 76.5625\n",
      "  batch 35 loss: 0.0029620987474918365 accuracy 76.875\n",
      "  batch 40 loss: 0.0037600598335266115 accuracy 76.40625\n",
      "  batch 5 loss: 0.00531537264585495 accuracy 79.375\n",
      "  batch 10 loss: 0.004539352297782898 accuracy 72.8125\n",
      "  batch 15 loss: 0.0032131789326667786 accuracy 73.75\n",
      "  batch 20 loss: 0.003190254509449005 accuracy 75.625\n",
      "  batch 25 loss: 0.002914086729288101 accuracy 76.375\n",
      "  batch 30 loss: 0.003675562709569931 accuracy 76.45833333333333\n",
      "  batch 35 loss: 0.003184260010719299 accuracy 76.69642857142857\n",
      "  batch 40 loss: 0.003589727759361267 accuracy 76.484375\n",
      "  batch 5 loss: 0.005899473935365677 accuracy 78.75\n",
      "  batch 10 loss: 0.0031366362869739532 accuracy 76.875\n",
      "  batch 15 loss: 0.0038488221168518064 accuracy 75.0\n",
      "  batch 20 loss: 0.0031677592247724533 accuracy 75.15625\n",
      "  batch 25 loss: 0.003201421648263931 accuracy 76.0\n",
      "  batch 30 loss: 0.00333929705619812 accuracy 75.52083333333333\n",
      "  batch 35 loss: 0.0035240287184715273 accuracy 75.71428571428571\n",
      "  batch 40 loss: 0.003964592218399048 accuracy 75.3125\n",
      "  batch 5 loss: 0.006007894426584243 accuracy 81.25\n",
      "  batch 10 loss: 0.0033579261302948 accuracy 78.75\n",
      "  batch 15 loss: 0.0032524808645248413 accuracy 78.125\n",
      "  batch 20 loss: 0.0035758599042892457 accuracy 76.875\n",
      "  batch 25 loss: 0.003322037935256958 accuracy 76.25\n",
      "  batch 30 loss: 0.0024173127710819245 accuracy 77.39583333333333\n",
      "  batch 35 loss: 0.0037871655225753783 accuracy 76.875\n",
      "  batch 40 loss: 0.0032706117630004884 accuracy 77.265625\n",
      "  batch 5 loss: 0.006025057017803192 accuracy 76.875\n",
      "  batch 10 loss: 0.0035134923458099367 accuracy 75.9375\n",
      "  batch 15 loss: 0.0035631212294101717 accuracy 76.25\n",
      "  batch 20 loss: 0.003730548977851868 accuracy 75.15625\n",
      "  batch 25 loss: 0.0032023680210113525 accuracy 75.75\n",
      "  batch 30 loss: 0.003372353404760361 accuracy 75.41666666666667\n",
      "  batch 35 loss: 0.0027888299524784087 accuracy 75.71428571428571\n",
      "  batch 40 loss: 0.00327674600481987 accuracy 75.859375\n",
      "  batch 5 loss: 0.006185240209102631 accuracy 71.25\n",
      "  batch 10 loss: 0.0028963997066020967 accuracy 74.0625\n",
      "  batch 15 loss: 0.002142135351896286 accuracy 77.08333333333333\n",
      "  batch 20 loss: 0.0038665140867233275 accuracy 75.15625\n",
      "  batch 25 loss: 0.0026667600572109224 accuracy 76.5\n",
      "  batch 30 loss: 0.0033164502382278444 accuracy 76.35416666666667\n",
      "  batch 35 loss: 0.002953864872455597 accuracy 76.33928571428571\n",
      "  batch 40 loss: 0.003652456820011139 accuracy 75.859375\n",
      "  batch 5 loss: 0.005850978821516037 accuracy 73.125\n",
      "  batch 10 loss: 0.00325327005982399 accuracy 74.375\n",
      "  batch 15 loss: 0.003326303005218506 accuracy 75.41666666666667\n",
      "  batch 20 loss: 0.0032744657397270204 accuracy 75.3125\n",
      "  batch 25 loss: 0.003935303986072541 accuracy 74.125\n",
      "  batch 30 loss: 0.002563832014799118 accuracy 75.0\n",
      "  batch 35 loss: 0.0032163169384002684 accuracy 74.91071428571429\n",
      "  batch 40 loss: 0.0025226429998874665 accuracy 75.859375\n",
      "  batch 5 loss: 0.0046492512226104735 accuracy 80.625\n",
      "  batch 10 loss: 0.003951184988021851 accuracy 75.9375\n",
      "  batch 15 loss: 0.0037190916538238526 accuracy 73.75\n",
      "  batch 20 loss: 0.002910463273525238 accuracy 74.84375\n",
      "  batch 25 loss: 0.003652455449104309 accuracy 74.375\n",
      "  batch 30 loss: 0.0030704694986343384 accuracy 74.89583333333333\n",
      "  batch 35 loss: 0.0026341916024684906 accuracy 75.98214285714286\n",
      "  batch 40 loss: 0.003539194196462631 accuracy 76.09375\n",
      "  batch 5 loss: 0.005231033354997635 accuracy 78.75\n",
      "  batch 10 loss: 0.0029378497302532196 accuracy 77.5\n",
      "  batch 15 loss: 0.003349300414323807 accuracy 76.66666666666667\n",
      "  batch 20 loss: 0.0030210511088371275 accuracy 76.875\n",
      "  batch 25 loss: 0.0035461624562740327 accuracy 75.875\n",
      "  batch 30 loss: 0.0032371144294738767 accuracy 75.83333333333333\n",
      "  batch 35 loss: 0.0029836136102676394 accuracy 75.625\n",
      "  batch 40 loss: 0.002698284387588501 accuracy 76.171875\n",
      "  batch 5 loss: 0.006302842557430267 accuracy 75.625\n",
      "  batch 10 loss: 0.002748747646808624 accuracy 79.0625\n",
      "  batch 15 loss: 0.003025232821702957 accuracy 78.95833333333333\n",
      "  batch 20 loss: 0.0034362368583679198 accuracy 77.65625\n",
      "  batch 25 loss: 0.002572362393140793 accuracy 78.375\n",
      "  batch 30 loss: 0.0028606903851032257 accuracy 78.4375\n",
      "  batch 35 loss: 0.003070538580417633 accuracy 78.125\n",
      "  batch 40 loss: 0.00395200514793396 accuracy 77.578125\n",
      "  batch 5 loss: 0.005270640149712563 accuracy 78.75\n",
      "  batch 10 loss: 0.003765124410390854 accuracy 77.8125\n",
      "  batch 15 loss: 0.003397127866744995 accuracy 76.875\n",
      "  batch 20 loss: 0.0029900352358818052 accuracy 77.5\n",
      "  batch 25 loss: 0.003480756103992462 accuracy 77.375\n",
      "  batch 30 loss: 0.003544520288705826 accuracy 76.77083333333333\n",
      "  batch 35 loss: 0.003500946342945099 accuracy 76.16071428571429\n",
      "  batch 40 loss: 0.002936658471822739 accuracy 75.859375\n",
      "  batch 5 loss: 0.004971426397562027 accuracy 83.125\n",
      "  batch 10 loss: 0.0035269163250923156 accuracy 80.3125\n",
      "  batch 15 loss: 0.002643776446580887 accuracy 81.25\n",
      "  batch 20 loss: 0.0027922368943691252 accuracy 80.78125\n",
      "  batch 25 loss: 0.0035149122178554535 accuracy 79.25\n",
      "  batch 30 loss: 0.002984589159488678 accuracy 78.4375\n",
      "  batch 35 loss: 0.003962055444717407 accuracy 77.23214285714286\n",
      "  batch 40 loss: 0.003257765233516693 accuracy 77.421875\n",
      "  batch 5 loss: 0.005865722507238388 accuracy 77.5\n",
      "  batch 10 loss: 0.0035001083612442017 accuracy 77.5\n",
      "  batch 15 loss: 0.003655659794807434 accuracy 76.25\n",
      "  batch 20 loss: 0.0033308249711990357 accuracy 76.09375\n",
      "  batch 25 loss: 0.0032906063497066497 accuracy 76.75\n",
      "  batch 30 loss: 0.0028025354743003847 accuracy 77.1875\n",
      "  batch 35 loss: 0.003309084445238113 accuracy 77.41071428571429\n",
      "  batch 40 loss: 0.002999467730522156 accuracy 77.421875\n",
      "  batch 5 loss: 0.0058458092212677 accuracy 78.125\n",
      "  batch 10 loss: 0.0033366174101829528 accuracy 75.9375\n",
      "  batch 15 loss: 0.003163325250148773 accuracy 76.04166666666667\n",
      "  batch 20 loss: 0.003302189886569977 accuracy 75.46875\n",
      "  batch 25 loss: 0.0029860801696777344 accuracy 75.75\n",
      "  batch 30 loss: 0.0031811909675598144 accuracy 76.66666666666667\n",
      "  batch 35 loss: 0.0036990138292312623 accuracy 76.33928571428571\n",
      "  batch 40 loss: 0.002812765434384346 accuracy 77.03125\n",
      "  batch 5 loss: 0.006362702280282974 accuracy 75.0\n",
      "  batch 10 loss: 0.0036935103535652163 accuracy 75.0\n",
      "  batch 15 loss: 0.0029234488010406495 accuracy 76.25\n",
      "  batch 20 loss: 0.003035936623811722 accuracy 76.5625\n",
      "  batch 25 loss: 0.002761715203523636 accuracy 77.75\n",
      "  batch 30 loss: 0.003531039357185364 accuracy 77.39583333333333\n",
      "  batch 35 loss: 0.0036814711689949035 accuracy 76.51785714285714\n",
      "  batch 40 loss: 0.003677399218082428 accuracy 76.015625\n",
      "  batch 5 loss: 0.005590380802750587 accuracy 78.125\n",
      "  batch 10 loss: 0.003547125995159149 accuracy 76.875\n",
      "  batch 15 loss: 0.0032691019773483277 accuracy 76.45833333333333\n",
      "  batch 20 loss: 0.0029788279235363007 accuracy 77.65625\n",
      "  batch 25 loss: 0.0037002611756324767 accuracy 76.375\n",
      "  batch 30 loss: 0.0030866075456142425 accuracy 76.14583333333333\n",
      "  batch 35 loss: 0.002571979314088821 accuracy 77.05357142857143\n",
      "  batch 40 loss: 0.003379984676837921 accuracy 76.5625\n",
      "  batch 5 loss: 0.004634482324123382 accuracy 78.125\n",
      "  batch 10 loss: 0.0028468506932258606 accuracy 79.6875\n",
      "  batch 15 loss: 0.0032302715182304384 accuracy 78.33333333333333\n",
      "  batch 20 loss: 0.002668287366628647 accuracy 79.6875\n",
      "  batch 25 loss: 0.0032940295338630674 accuracy 78.5\n",
      "  batch 30 loss: 0.0032091550529003143 accuracy 78.22916666666667\n",
      "  batch 35 loss: 0.0031634284853935242 accuracy 77.94642857142857\n",
      "  batch 40 loss: 0.0033476017117500304 accuracy 77.8125\n",
      "  batch 5 loss: 0.003918149076402188 accuracy 86.875\n",
      "  batch 10 loss: 0.003503122925758362 accuracy 80.9375\n",
      "  batch 15 loss: 0.0025104729533195497 accuracy 81.25\n",
      "  batch 20 loss: 0.0024820215702056883 accuracy 81.71875\n",
      "  batch 25 loss: 0.0030500672459602357 accuracy 80.5\n",
      "  batch 30 loss: 0.0028428183794021607 accuracy 80.83333333333333\n",
      "  batch 35 loss: 0.0029149585664272307 accuracy 80.98214285714286\n",
      "  batch 40 loss: 0.0036890416741371156 accuracy 79.84375\n",
      "  batch 5 loss: 0.0055757929086685185 accuracy 77.5\n",
      "  batch 10 loss: 0.002357790768146515 accuracy 80.625\n",
      "  batch 15 loss: 0.0027142036259174347 accuracy 79.58333333333333\n",
      "  batch 20 loss: 0.003211209535598755 accuracy 79.21875\n",
      "  batch 25 loss: 0.002475588619709015 accuracy 80.0\n",
      "  batch 30 loss: 0.002469347149133682 accuracy 80.10416666666667\n",
      "  batch 35 loss: 0.0032896885871887206 accuracy 79.19642857142857\n",
      "  batch 40 loss: 0.0028139254450798034 accuracy 78.90625\n",
      "  batch 5 loss: 0.00488263675570488 accuracy 78.75\n",
      "  batch 10 loss: 0.00344001841545105 accuracy 75.9375\n",
      "  batch 15 loss: 0.003024595379829407 accuracy 75.625\n",
      "  batch 20 loss: 0.0024740875214338304 accuracy 77.03125\n",
      "  batch 25 loss: 0.002935061663389206 accuracy 77.5\n",
      "  batch 30 loss: 0.0026460703611373903 accuracy 78.33333333333333\n",
      "  batch 35 loss: 0.0030892851650714875 accuracy 78.03571428571429\n",
      "  batch 40 loss: 0.0028830993473529815 accuracy 78.046875\n",
      "  batch 5 loss: 0.006034907042980194 accuracy 74.375\n",
      "  batch 10 loss: 0.002402797818183899 accuracy 78.4375\n",
      "  batch 15 loss: 0.0032380616962909697 accuracy 77.5\n",
      "  batch 20 loss: 0.003252327650785446 accuracy 77.96875\n",
      "  batch 25 loss: 0.0025254324972629545 accuracy 78.75\n",
      "  batch 30 loss: 0.003180681049823761 accuracy 78.54166666666667\n",
      "  batch 35 loss: 0.0031897026896476745 accuracy 78.30357142857143\n",
      "  batch 40 loss: 0.0036874827146530153 accuracy 77.65625\n",
      "  batch 5 loss: 0.004731748670339584 accuracy 76.25\n",
      "  batch 10 loss: 0.00357920503616333 accuracy 75.9375\n",
      "  batch 15 loss: 0.0028185431361198426 accuracy 77.08333333333333\n",
      "  batch 20 loss: 0.0034232003390789034 accuracy 76.09375\n",
      "  batch 25 loss: 0.0031701512336730956 accuracy 77.0\n",
      "  batch 30 loss: 0.003151886910200119 accuracy 76.875\n",
      "  batch 35 loss: 0.0026015030145645143 accuracy 77.05357142857143\n",
      "  batch 40 loss: 0.0029669322967529298 accuracy 77.34375\n",
      "  batch 5 loss: 0.004647984504699707 accuracy 81.25\n",
      "  batch 10 loss: 0.0029923409521579744 accuracy 79.375\n",
      "  batch 15 loss: 0.003339045524597168 accuracy 77.5\n",
      "  batch 20 loss: 0.0030150723457336424 accuracy 78.125\n",
      "  batch 25 loss: 0.0026769699156284333 accuracy 78.25\n",
      "  batch 30 loss: 0.0033248313665390013 accuracy 78.22916666666667\n",
      "  batch 35 loss: 0.0023775968849658966 accuracy 78.92857142857143\n",
      "  batch 40 loss: 0.0031797259896993637 accuracy 78.671875\n",
      "  batch 5 loss: 0.005470371156930923 accuracy 80.625\n",
      "  batch 10 loss: 0.00324416920542717 accuracy 77.1875\n",
      "  batch 15 loss: 0.0032006167769432067 accuracy 77.70833333333333\n",
      "  batch 20 loss: 0.002399174392223358 accuracy 78.75\n",
      "  batch 25 loss: 0.0029471184611320495 accuracy 78.875\n",
      "  batch 30 loss: 0.003438006192445755 accuracy 77.8125\n",
      "  batch 35 loss: 0.003292359620332718 accuracy 77.76785714285714\n",
      "  batch 40 loss: 0.0027718804478645324 accuracy 78.203125\n",
      "  batch 5 loss: 0.005139334112405777 accuracy 78.75\n",
      "  batch 10 loss: 0.002656462222337723 accuracy 80.0\n",
      "  batch 15 loss: 0.0029409870207309724 accuracy 78.75\n",
      "  batch 20 loss: 0.0031758833229541777 accuracy 78.28125\n",
      "  batch 25 loss: 0.003544776558876038 accuracy 77.625\n",
      "  batch 30 loss: 0.002408119708299637 accuracy 78.33333333333333\n",
      "  batch 35 loss: 0.0029694193601608274 accuracy 78.66071428571429\n",
      "  batch 40 loss: 0.003364150583744049 accuracy 77.96875\n",
      "  batch 5 loss: 0.005541473984718322 accuracy 75.625\n",
      "  batch 10 loss: 0.0024872408509254455 accuracy 79.6875\n",
      "  batch 15 loss: 0.003134809345006943 accuracy 78.75\n",
      "  batch 20 loss: 0.002212909534573555 accuracy 80.3125\n",
      "  batch 25 loss: 0.0029787734746932982 accuracy 80.25\n",
      "  batch 30 loss: 0.003145976960659027 accuracy 80.10416666666667\n",
      "  batch 35 loss: 0.002644055053591728 accuracy 80.0\n",
      "  batch 40 loss: 0.0029168623089790343 accuracy 79.921875\n",
      "  batch 5 loss: 0.005311192870140076 accuracy 84.375\n",
      "  batch 10 loss: 0.003535257339477539 accuracy 79.6875\n",
      "  batch 15 loss: 0.002676186352968216 accuracy 79.79166666666667\n",
      "  batch 20 loss: 0.0031598888635635375 accuracy 78.75\n",
      "  batch 25 loss: 0.0027099226415157316 accuracy 79.625\n",
      "  batch 30 loss: 0.0031801689863204955 accuracy 79.16666666666667\n",
      "  batch 35 loss: 0.003313205540180206 accuracy 78.48214285714286\n",
      "  batch 40 loss: 0.00304059699177742 accuracy 78.046875\n",
      "  batch 5 loss: 0.0057047770321369175 accuracy 76.875\n",
      "  batch 10 loss: 0.003180349379777908 accuracy 76.875\n",
      "  batch 15 loss: 0.0032788770794868467 accuracy 76.45833333333333\n",
      "  batch 20 loss: 0.0027022165060043334 accuracy 77.03125\n",
      "  batch 25 loss: 0.003000647038221359 accuracy 77.375\n",
      "  batch 30 loss: 0.0024544279873371126 accuracy 78.02083333333333\n",
      "  batch 35 loss: 0.003115030109882355 accuracy 78.03571428571429\n",
      "  batch 40 loss: 0.0024361923635005953 accuracy 78.59375\n",
      "  batch 5 loss: 0.004157032936811447 accuracy 82.5\n",
      "  batch 10 loss: 0.0027379985451698305 accuracy 80.9375\n",
      "  batch 15 loss: 0.0032663782238960266 accuracy 79.58333333333333\n",
      "  batch 20 loss: 0.0029339146614074706 accuracy 80.0\n",
      "  batch 25 loss: 0.002229305386543274 accuracy 80.875\n",
      "  batch 30 loss: 0.0032932235598564148 accuracy 80.20833333333333\n",
      "  batch 35 loss: 0.0030971272885799406 accuracy 80.08928571428571\n",
      "  batch 40 loss: 0.002639820218086243 accuracy 80.390625\n",
      "  batch 5 loss: 0.005237536013126373 accuracy 79.375\n",
      "  batch 10 loss: 0.0028749545216560364 accuracy 80.3125\n",
      "  batch 15 loss: 0.0028777015209198 accuracy 79.58333333333333\n",
      "  batch 20 loss: 0.002734613001346588 accuracy 79.6875\n",
      "  batch 25 loss: 0.0026061651408672334 accuracy 80.0\n",
      "  batch 30 loss: 0.002404424220323563 accuracy 80.52083333333333\n",
      "  batch 35 loss: 0.0038502769470214844 accuracy 79.10714285714286\n",
      "  batch 40 loss: 0.0027187030613422393 accuracy 78.828125\n",
      "  batch 5 loss: 0.004970111697912216 accuracy 81.25\n",
      "  batch 10 loss: 0.002615550607442856 accuracy 81.875\n",
      "  batch 15 loss: 0.0033707242608070373 accuracy 78.75\n",
      "  batch 20 loss: 0.0026594432592391966 accuracy 78.59375\n",
      "  batch 25 loss: 0.0027425761222839356 accuracy 78.375\n",
      "  batch 30 loss: 0.0031704832017421724 accuracy 78.02083333333333\n",
      "  batch 35 loss: 0.003111282259225845 accuracy 78.03571428571429\n",
      "  batch 40 loss: 0.0025074882954359053 accuracy 78.4375\n",
      "  batch 5 loss: 0.0055821293592453 accuracy 76.875\n",
      "  batch 10 loss: 0.0029309573769569397 accuracy 77.8125\n",
      "  batch 15 loss: 0.0024261630177497863 accuracy 78.33333333333333\n",
      "  batch 20 loss: 0.0026713778376579287 accuracy 78.90625\n",
      "  batch 25 loss: 0.002510438710451126 accuracy 79.375\n",
      "  batch 30 loss: 0.0021836469918489454 accuracy 79.89583333333333\n",
      "  batch 35 loss: 0.003463194966316223 accuracy 79.01785714285714\n",
      "  batch 40 loss: 0.002637572169303894 accuracy 78.828125\n",
      "  batch 5 loss: 0.005025406330823898 accuracy 81.875\n",
      "  batch 10 loss: 0.0028268944919109347 accuracy 80.3125\n",
      "  batch 15 loss: 0.002598745346069336 accuracy 80.20833333333333\n",
      "  batch 20 loss: 0.002428002506494522 accuracy 79.84375\n",
      "  batch 25 loss: 0.00258660688996315 accuracy 80.75\n",
      "  batch 30 loss: 0.0026777773797512054 accuracy 80.52083333333333\n",
      "  batch 35 loss: 0.0030854869782924654 accuracy 79.73214285714286\n",
      "  batch 40 loss: 0.0029728327095508576 accuracy 79.296875\n",
      "  batch 5 loss: 0.00572253605723381 accuracy 75.0\n",
      "  batch 10 loss: 0.002544480323791504 accuracy 77.8125\n",
      "  batch 15 loss: 0.003154597669839859 accuracy 78.33333333333333\n",
      "  batch 20 loss: 0.00269985693693161 accuracy 78.59375\n",
      "  batch 25 loss: 0.0034922842383384705 accuracy 78.0\n",
      "  batch 30 loss: 0.002280815809965134 accuracy 78.75\n",
      "  batch 35 loss: 0.003085722655057907 accuracy 78.75\n",
      "  batch 40 loss: 0.003646038442850113 accuracy 78.515625\n",
      "  batch 5 loss: 0.004786381542682648 accuracy 83.125\n",
      "  batch 10 loss: 0.003072747051715851 accuracy 80.0\n",
      "  batch 15 loss: 0.0027305175364017486 accuracy 79.375\n",
      "  batch 20 loss: 0.003430955410003662 accuracy 78.4375\n",
      "  batch 25 loss: 0.003479146659374237 accuracy 77.25\n",
      "  batch 30 loss: 0.003045468419790268 accuracy 77.70833333333333\n",
      "  batch 35 loss: 0.0025748354494571687 accuracy 78.30357142857143\n",
      "  batch 40 loss: 0.0025424563586711885 accuracy 78.828125\n",
      "  batch 5 loss: 0.004100276082754135 accuracy 86.875\n",
      "  batch 10 loss: 0.0025043509751558305 accuracy 85.3125\n",
      "  batch 15 loss: 0.003519277513027191 accuracy 80.41666666666667\n",
      "  batch 20 loss: 0.0026675959527492524 accuracy 79.84375\n",
      "  batch 25 loss: 0.002941024661064148 accuracy 79.75\n",
      "  batch 30 loss: 0.00300032114982605 accuracy 79.375\n",
      "  batch 35 loss: 0.0029767072200775147 accuracy 79.64285714285714\n",
      "  batch 40 loss: 0.0031499971747398375 accuracy 79.21875\n",
      "  batch 5 loss: 0.004593465656042099 accuracy 83.75\n",
      "  batch 10 loss: 0.0026494844406843186 accuracy 83.125\n",
      "  batch 15 loss: 0.003061529219150543 accuracy 81.25\n",
      "  batch 20 loss: 0.0028121104538440704 accuracy 80.46875\n",
      "  batch 25 loss: 0.003591377228498459 accuracy 79.25\n",
      "  batch 30 loss: 0.003082147628068924 accuracy 78.75\n",
      "  batch 35 loss: 0.0027870284616947176 accuracy 79.01785714285714\n",
      "  batch 40 loss: 0.0029794388115406034 accuracy 78.984375\n",
      "  batch 5 loss: 0.004424422770738601 accuracy 79.375\n",
      "  batch 10 loss: 0.0030088802576065062 accuracy 79.0625\n",
      "  batch 15 loss: 0.002954952597618103 accuracy 79.79166666666667\n",
      "  batch 20 loss: 0.0027154867649078368 accuracy 80.0\n",
      "  batch 25 loss: 0.0027151756286621096 accuracy 80.0\n",
      "  batch 30 loss: 0.0022955848872661592 accuracy 80.3125\n",
      "  batch 35 loss: 0.0032789965867996216 accuracy 79.73214285714286\n",
      "  batch 40 loss: 0.0029854571521282197 accuracy 79.6875\n",
      "  batch 5 loss: 0.005137778639793396 accuracy 77.5\n",
      "  batch 10 loss: 0.0026282211542129515 accuracy 77.5\n",
      "  batch 15 loss: 0.003051571875810623 accuracy 77.91666666666667\n",
      "  batch 20 loss: 0.002859614670276642 accuracy 78.4375\n",
      "  batch 25 loss: 0.002485499292612076 accuracy 79.625\n",
      "  batch 30 loss: 0.0028384990692138672 accuracy 79.58333333333333\n",
      "  batch 35 loss: 0.002979352414608002 accuracy 79.375\n",
      "  batch 40 loss: 0.0024889592230319976 accuracy 79.765625\n",
      "  batch 5 loss: 0.005926337778568267 accuracy 74.375\n",
      "  batch 10 loss: 0.0028440122902393342 accuracy 76.25\n",
      "  batch 15 loss: 0.0021478862911462784 accuracy 78.75\n",
      "  batch 20 loss: 0.00270458984375 accuracy 79.21875\n",
      "  batch 25 loss: 0.002694080412387848 accuracy 79.75\n",
      "  batch 30 loss: 0.0032818876802921293 accuracy 78.95833333333333\n",
      "  batch 35 loss: 0.0030220441520214083 accuracy 78.83928571428571\n",
      "  batch 40 loss: 0.002766106516122818 accuracy 79.140625\n",
      "  batch 5 loss: 0.005364723175764084 accuracy 79.375\n",
      "  batch 10 loss: 0.0029282103776931763 accuracy 78.75\n",
      "  batch 15 loss: 0.0029451583325862886 accuracy 79.79166666666667\n",
      "  batch 20 loss: 0.002576898545026779 accuracy 80.625\n",
      "  batch 25 loss: 0.0028324503898620604 accuracy 80.25\n",
      "  batch 30 loss: 0.0023974979519844055 accuracy 80.72916666666667\n",
      "  batch 35 loss: 0.0029194559156894683 accuracy 80.26785714285714\n",
      "  batch 40 loss: 0.0030953679382801054 accuracy 79.6875\n",
      "  batch 5 loss: 0.005197255492210388 accuracy 78.125\n",
      "  batch 10 loss: 0.003365785837173462 accuracy 78.75\n",
      "  batch 15 loss: 0.0023049111068248747 accuracy 80.0\n",
      "  batch 20 loss: 0.002399926036596298 accuracy 80.9375\n",
      "  batch 25 loss: 0.0029613216817379 accuracy 80.75\n",
      "  batch 30 loss: 0.003304988503456116 accuracy 79.89583333333333\n",
      "  batch 35 loss: 0.0027939135730266572 accuracy 79.375\n",
      "  batch 40 loss: 0.0024180303812026977 accuracy 79.921875\n",
      "  batch 5 loss: 0.005267321318387985 accuracy 78.125\n",
      "  batch 10 loss: 0.0028898749351501463 accuracy 78.125\n",
      "  batch 15 loss: 0.0024350519478321076 accuracy 79.375\n",
      "  batch 20 loss: 0.003273918956518173 accuracy 79.21875\n",
      "  batch 25 loss: 0.003157171905040741 accuracy 79.0\n",
      "  batch 30 loss: 0.002781738460063934 accuracy 79.27083333333333\n",
      "  batch 35 loss: 0.002283885955810547 accuracy 79.91071428571429\n",
      "  batch 40 loss: 0.002989176094532013 accuracy 79.609375\n",
      "  batch 5 loss: 0.005379219114780426 accuracy 77.5\n",
      "  batch 10 loss: 0.003268783450126648 accuracy 75.625\n",
      "  batch 15 loss: 0.002590269535779953 accuracy 78.125\n",
      "  batch 20 loss: 0.0023868667185306548 accuracy 80.0\n",
      "  batch 25 loss: 0.003106442332267761 accuracy 79.625\n",
      "  batch 30 loss: 0.0021488597840070723 accuracy 80.41666666666667\n",
      "  batch 35 loss: 0.0026854830086231233 accuracy 80.625\n",
      "  batch 40 loss: 0.002682387590408325 accuracy 80.703125\n",
      "  batch 5 loss: 0.0047387231588363644 accuracy 80.0\n",
      "  batch 10 loss: 0.0025048209130764006 accuracy 80.3125\n",
      "  batch 15 loss: 0.002752680599689484 accuracy 80.625\n",
      "  batch 20 loss: 0.0028830183148384095 accuracy 79.84375\n",
      "  batch 25 loss: 0.0032571693360805513 accuracy 79.25\n",
      "  batch 30 loss: 0.0025539686679840086 accuracy 79.16666666666667\n",
      "  batch 35 loss: 0.0021226440370082857 accuracy 79.91071428571429\n",
      "  batch 40 loss: 0.0034802784323692323 accuracy 78.90625\n",
      "  batch 5 loss: 0.004850124776363373 accuracy 80.0\n",
      "  batch 10 loss: 0.002509442687034607 accuracy 81.25\n",
      "  batch 15 loss: 0.002686875522136688 accuracy 81.66666666666667\n",
      "  batch 20 loss: 0.0028241426348686216 accuracy 81.25\n",
      "  batch 25 loss: 0.003342482626438141 accuracy 80.5\n",
      "  batch 30 loss: 0.0028901515007019045 accuracy 80.0\n",
      "  batch 35 loss: 0.0031627957820892336 accuracy 79.28571428571429\n",
      "  batch 40 loss: 0.0028096724748611452 accuracy 79.453125\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "epochs = 100\n",
    "learning_rate = 0.001\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "running_loss = 0.\n",
    "last_loss = 0.\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for i,data in enumerate(train_loader):\n",
    "        batch_X, batch_Y = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = loss_fn(outputs, batch_Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)  # Get the predicted class\n",
    "        total += batch_Y.size(0)  # Total number of samples\n",
    "        correct += (predicted == batch_Y).sum().item()  # Count correct predictions\n",
    "\n",
    "        accuracy = 100 * correct / total  # Calculate accuracy\n",
    "        running_loss += loss.item()\n",
    "        if i % 5 == 4:\n",
    "            last_loss = running_loss / 1000 # loss per batch\n",
    "            print('  batch {} loss: {} accuracy {}'.format(i + 1, last_loss, accuracy))\n",
    "            running_loss = 0."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chord_env",
   "language": "python",
   "name": "chord_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
